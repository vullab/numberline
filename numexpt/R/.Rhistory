filter(trial %in% comparison.trials)
# compare magnitude of trial.i to previous trials
curr.trial.mag.mean = single.subj$num_dots[single.subj$trial == trial.i]
prev.vals = prev.vals %>%
mutate(p.mag.greater = 1 - pnorm(0, mean = log10(curr.trial.mag.mean) - log10(num_dots), sd = sqrt(2 * PERCEIVED_DOTS_NOISE_SD)))
# discretize possible answer estimates, set log likelihood at each value to be either p.mag.greater or 1 - p.mag.greater
# use matrix with a row for each of the previous trials and a column for each candidate estimate value.
# each row, col element in X is the log likelihood that the magnitude on the current trial maps to the column value, given the magnitude
#   and corresponding estimate in that row's trial
X = matrix(0, nrow = ESTIMATE_CALIBRATION, ncol = MAX_ESTIMATE) # Initialize matrix for storing log likelihoods
# matrix storing proability in each col that magnitude on this trial is < magnitude in trial indicated by that row
P = matrix(rep(1 - prev.vals$p.mag.greater[1:ESTIMATE_CALIBRATION], MAX_ESTIMATE), nrow = ESTIMATE_CALIBRATION)
# matrix storing numerical estimate generated for each previous trial
B = matrix(rep(floor(prev.vals$answer_estimate[1:ESTIMATE_CALIBRATION]), 1000), nrow = ESTIMATE_CALIBRATION)
X[A < B] = log10(P[A < B])
X[A >= B] = log10(1 - P[A >= B])
# across each previous trial that we've calculated a log likelihood vector for above, calculate aggregate likelihood for estimates
new.loglik = data.frame('number.est' = seq(1:MAX_ESTIMATE), 'sum.loglik' = colSums(X))
# process log likelihoods obtained above (add constant factor, re-convert to probability space, and normalize)
new.loglik = new.loglik %>%
mutate(prior = number.est ^ PRIOR_EXP,
prior.norm = prior / sum(prior),
sum.loglik = sum.loglik - max(sum.loglik),  #add a constant C to each value in new.loglik to make it more reasonable
loglik.probability.raw = 10 ^ sum.loglik, # reconvert out of log space
posterior.raw = loglik.probability.raw * prior.norm, # multiply loglik by the prior
posterior.norm = posterior.raw / sum(posterior.raw)) # normalize
# Three different ways of generating a number estimate are each included below (sample, posterior mean, posterior median)
# 1. sample estimate from the posterior
# estimate = with(new.loglik, sample(number.est, 1, prob = posterior.norm))
# 2. use the posterior mean as our estimate
# estimate = sum(new.loglik$number.est * new.loglik$posterior.norm)
# 3. use the median as our estimate (following Griffiths, Tenenbaum 2006)
estimate = new.loglik %>%
mutate(post_sum = cumsum(posterior.norm)) %>%
filter(post_sum <= 0.5) %>%
summarize(est = max(number.est)) %>%
pull(est)
print(paste("-> estimate: ", estimate))
print(paste("-> true number: ", single.subj$num_dots[single.subj$trial == trial.i]))
# print(paste("-> magnitude est: ", curr.trial.mag.mean))
single.subj$answer_estimate[single.subj$trial == trial.i] = estimate
}
}
#for (trial.i in seq(1, ESTIMATE_CALIBRATION + 10)) { # iterate to one past calibrated point
for (trial.i in seq(1, max(single.subj$trial))) { # over all trials
print(paste("trial: ", trial.i)) # show progress
if (trial.i <= ESTIMATE_CALIBRATION) {
# set first ESTIMATE_CALIBRATION values to be a sample from a distribution around the true number of dots
# NB: samples in log space with low SD so that samples will be closer to real numbers at low n, farther at high n
# single.subj$answer_estimate[trial.i] = 10 ^ rnorm(1, log10(single.subj$num_dots[trial.i]), PERCEIVED_DOTS_NOISE_SD)
print(paste("-> estimate: ", single.subj$num_dots[trial.i]))
single.subj$answer_estimate[trial.i] = single.subj$num_dots[trial.i] # use exact number for debugging
} else {
# fetch previous trials for magnitude comparison
comparison.trials = seq(trial.i - ESTIMATE_CALIBRATION, trial.i - 1)
prev.vals = single.subj %>%
filter(trial %in% comparison.trials)
# compare magnitude of trial.i to previous trials
curr.trial.mag.mean = single.subj$num_dots[single.subj$trial == trial.i]
prev.vals = prev.vals %>%
mutate(p.mag.greater = 1 - pnorm(0, mean = log10(curr.trial.mag.mean) - log10(num_dots), sd = sqrt(2 * PERCEIVED_DOTS_NOISE_SD)))
# discretize possible answer estimates, set log likelihood at each value to be either p.mag.greater or 1 - p.mag.greater
# use matrix with a row for each of the previous trials and a column for each candidate estimate value.
# each row, col element in X is the log likelihood that the magnitude on the current trial maps to the column value, given the magnitude
#   and corresponding estimate in that row's trial
X = matrix(0, nrow = ESTIMATE_CALIBRATION, ncol = MAX_ESTIMATE) # Initialize matrix for storing log likelihoods
# matrix storing proability in each col that magnitude on this trial is < magnitude in trial indicated by that row
P = matrix(rep(1 - prev.vals$p.mag.greater[1:ESTIMATE_CALIBRATION], MAX_ESTIMATE), nrow = ESTIMATE_CALIBRATION)
# matrix storing numerical estimate generated for each previous trial
B = matrix(rep(floor(prev.vals$answer_estimate[1:ESTIMATE_CALIBRATION]), 1000), nrow = ESTIMATE_CALIBRATION)
X[A < B] = log10(P[A < B])
X[A >= B] = log10(1 - P[A >= B])
# across each previous trial that we've calculated a log likelihood vector for above, calculate aggregate likelihood for estimates
new.loglik = data.frame('number.est' = seq(1:MAX_ESTIMATE), 'sum.loglik' = colSums(X))
# process log likelihoods obtained above (add constant factor, re-convert to probability space, and normalize)
new.loglik = new.loglik %>%
mutate(prior = number.est ^ PRIOR_EXP,
prior.norm = prior / sum(prior),
sum.loglik = sum.loglik - max(sum.loglik),  #add a constant C to each value in new.loglik to make it more reasonable
loglik.probability.raw = 10 ^ sum.loglik, # reconvert out of log space
posterior.raw = loglik.probability.raw * prior.norm, # multiply loglik by the prior
posterior.norm = posterior.raw / sum(posterior.raw)) # normalize
# Three different ways of generating a number estimate are each included below (sample, posterior mean, posterior median)
# 1. sample estimate from the posterior
# estimate = with(new.loglik, sample(number.est, 1, prob = posterior.norm))
# 2. use the posterior mean as our estimate
# estimate = sum(new.loglik$number.est * new.loglik$posterior.norm)
# 3. use the median as our estimate (following Griffiths, Tenenbaum 2006)
estimate = new.loglik %>%
mutate(post_sum = cumsum(posterior.norm)) %>%
filter(post_sum <= 0.5) %>%
summarize(est = max(number.est)) %>%
pull(est)
print(paste('-> estimate: ', estimate))
print(paste("-> true number: ", single.subj$num_dots[single.subj$trial == trial.i]))
# print(paste("-> magnitude est: ", curr.trial.mag.mean))
single.subj$answer_estimate[single.subj$trial == trial.i] = estimate
}
}
#for (trial.i in seq(1, ESTIMATE_CALIBRATION + 10)) { # iterate to one past calibrated point
results = data.frame('trial' = numeric(),
'estimate' = numeric(),
'true number' = numeric())
for (trial.i in seq(1, max(single.subj$trial))) { # over all trials
print(paste("trial: ", trial.i)) # show progress
results$trial = c(results$trial, trial.i)
if (trial.i <= ESTIMATE_CALIBRATION) {
# set first ESTIMATE_CALIBRATION values to be a sample from a distribution around the true number of dots
# NB: samples in log space with low SD so that samples will be closer to real numbers at low n, farther at high n
# single.subj$answer_estimate[trial.i] = 10 ^ rnorm(1, log10(single.subj$num_dots[trial.i]), PERCEIVED_DOTS_NOISE_SD)
print(paste("-> estimate: ", single.subj$num_dots[trial.i]))
single.subj$answer_estimate[trial.i] = single.subj$num_dots[trial.i] # use exact number for debugging
} else {
# fetch previous trials for magnitude comparison
comparison.trials = seq(trial.i - ESTIMATE_CALIBRATION, trial.i - 1)
prev.vals = single.subj %>%
filter(trial %in% comparison.trials)
# compare magnitude of trial.i to previous trials
curr.trial.mag.mean = single.subj$num_dots[single.subj$trial == trial.i]
prev.vals = prev.vals %>%
mutate(p.mag.greater = 1 - pnorm(0, mean = log10(curr.trial.mag.mean) - log10(num_dots), sd = sqrt(2 * PERCEIVED_DOTS_NOISE_SD)))
# discretize possible answer estimates, set log likelihood at each value to be either p.mag.greater or 1 - p.mag.greater
# use matrix with a row for each of the previous trials and a column for each candidate estimate value.
# each row, col element in X is the log likelihood that the magnitude on the current trial maps to the column value, given the magnitude
#   and corresponding estimate in that row's trial
X = matrix(0, nrow = ESTIMATE_CALIBRATION, ncol = MAX_ESTIMATE) # Initialize matrix for storing log likelihoods
# matrix storing proability in each col that magnitude on this trial is < magnitude in trial indicated by that row
P = matrix(rep(1 - prev.vals$p.mag.greater[1:ESTIMATE_CALIBRATION], MAX_ESTIMATE), nrow = ESTIMATE_CALIBRATION)
# matrix storing numerical estimate generated for each previous trial
B = matrix(rep(floor(prev.vals$answer_estimate[1:ESTIMATE_CALIBRATION]), 1000), nrow = ESTIMATE_CALIBRATION)
X[A < B] = log10(P[A < B])
X[A >= B] = log10(1 - P[A >= B])
# across each previous trial that we've calculated a log likelihood vector for above, calculate aggregate likelihood for estimates
new.loglik = data.frame('number.est' = seq(1:MAX_ESTIMATE), 'sum.loglik' = colSums(X))
# process log likelihoods obtained above (add constant factor, re-convert to probability space, and normalize)
new.loglik = new.loglik %>%
mutate(prior = number.est ^ PRIOR_EXP,
prior.norm = prior / sum(prior),
sum.loglik = sum.loglik - max(sum.loglik),  #add a constant C to each value in new.loglik to make it more reasonable
loglik.probability.raw = 10 ^ sum.loglik, # reconvert out of log space
posterior.raw = loglik.probability.raw * prior.norm, # multiply loglik by the prior
posterior.norm = posterior.raw / sum(posterior.raw)) # normalize
# Three different ways of generating a number estimate are each included below (sample, posterior mean, posterior median)
# 1. sample estimate from the posterior
# estimate = with(new.loglik, sample(number.est, 1, prob = posterior.norm))
# 2. use the posterior mean as our estimate
# estimate = sum(new.loglik$number.est * new.loglik$posterior.norm)
# 3. use the median as our estimate (following Griffiths, Tenenbaum 2006)
estimate = new.loglik %>%
mutate(post_sum = cumsum(posterior.norm)) %>%
filter(post_sum <= 0.5) %>%
summarize(est = max(number.est)) %>%
pull(est)
print(paste("-> estimate: ", estimate))
print(paste("-> true number: ", single.subj$num_dots[single.subj$trial == trial.i]))
# print(paste("-> magnitude est: ", curr.trial.mag.mean))
single.subj$answer_estimate[single.subj$trial == trial.i] = estimate
}
}
results = data.frame('trial' = seq(1, ESTIMATE_CALIBRATION),
'estimate' = numeric(),
'true number' = numeric())
results = data.frame('trial' = seq(1, max(single.subj$trial)),
'estimate' = numeric(),
'true number' = numeric())
results = data.frame('trial' = seq(1, max(single.subj$trial)),
'estimate' = 0,
'true number' = 0)
#for (trial.i in seq(1, ESTIMATE_CALIBRATION + 10)) { # iterate to one past calibrated point
for (trial.i in seq(1, max(single.subj$trial))) { # over all trials
print(paste("trial: ", trial.i)) # show progress
results$trial = c(results$trial, trial.i)
if (trial.i <= ESTIMATE_CALIBRATION) {
# set first ESTIMATE_CALIBRATION values to be a sample from a distribution around the true number of dots
# NB: samples in log space with low SD so that samples will be closer to real numbers at low n, farther at high n
# single.subj$answer_estimate[trial.i] = 10 ^ rnorm(1, log10(single.subj$num_dots[trial.i]), PERCEIVED_DOTS_NOISE_SD)
print(paste("-> estimate: ", single.subj$num_dots[trial.i]))
single.subj$answer_estimate[trial.i] = single.subj$num_dots[trial.i] # use exact number for debugging
} else {
# fetch previous trials for magnitude comparison
comparison.trials = seq(trial.i - ESTIMATE_CALIBRATION, trial.i - 1)
prev.vals = single.subj %>%
filter(trial %in% comparison.trials)
# compare magnitude of trial.i to previous trials
curr.trial.mag.mean = single.subj$num_dots[single.subj$trial == trial.i]
prev.vals = prev.vals %>%
mutate(p.mag.greater = 1 - pnorm(0, mean = log10(curr.trial.mag.mean) - log10(num_dots), sd = sqrt(2 * PERCEIVED_DOTS_NOISE_SD)))
# discretize possible answer estimates, set log likelihood at each value to be either p.mag.greater or 1 - p.mag.greater
# use matrix with a row for each of the previous trials and a column for each candidate estimate value.
# each row, col element in X is the log likelihood that the magnitude on the current trial maps to the column value, given the magnitude
#   and corresponding estimate in that row's trial
X = matrix(0, nrow = ESTIMATE_CALIBRATION, ncol = MAX_ESTIMATE) # Initialize matrix for storing log likelihoods
# matrix storing proability in each col that magnitude on this trial is < magnitude in trial indicated by that row
P = matrix(rep(1 - prev.vals$p.mag.greater[1:ESTIMATE_CALIBRATION], MAX_ESTIMATE), nrow = ESTIMATE_CALIBRATION)
# matrix storing numerical estimate generated for each previous trial
B = matrix(rep(floor(prev.vals$answer_estimate[1:ESTIMATE_CALIBRATION]), 1000), nrow = ESTIMATE_CALIBRATION)
X[A < B] = log10(P[A < B])
X[A >= B] = log10(1 - P[A >= B])
# across each previous trial that we've calculated a log likelihood vector for above, calculate aggregate likelihood for estimates
new.loglik = data.frame('number.est' = seq(1:MAX_ESTIMATE), 'sum.loglik' = colSums(X))
# process log likelihoods obtained above (add constant factor, re-convert to probability space, and normalize)
new.loglik = new.loglik %>%
mutate(prior = number.est ^ PRIOR_EXP,
prior.norm = prior / sum(prior),
sum.loglik = sum.loglik - max(sum.loglik),  #add a constant C to each value in new.loglik to make it more reasonable
loglik.probability.raw = 10 ^ sum.loglik, # reconvert out of log space
posterior.raw = loglik.probability.raw * prior.norm, # multiply loglik by the prior
posterior.norm = posterior.raw / sum(posterior.raw)) # normalize
# Three different ways of generating a number estimate are each included below (sample, posterior mean, posterior median)
# 1. sample estimate from the posterior
# estimate = with(new.loglik, sample(number.est, 1, prob = posterior.norm))
# 2. use the posterior mean as our estimate
# estimate = sum(new.loglik$number.est * new.loglik$posterior.norm)
# 3. use the median as our estimate (following Griffiths, Tenenbaum 2006)
estimate = new.loglik %>%
mutate(post_sum = cumsum(posterior.norm)) %>%
filter(post_sum <= 0.5) %>%
summarize(est = max(number.est)) %>%
pull(est)
print(paste("-> estimate: ", estimate))
print(paste("-> true number: ", single.subj$num_dots[single.subj$trial == trial.i]))
# print(paste("-> magnitude est: ", curr.trial.mag.mean))
single.subj$answer_estimate[single.subj$trial == trial.i] = estimate
}
}
results = data.frame('trial' = seq(1, max(single.subj$trial)),
'estimate' = 0,
'true number' = 0)
#for (trial.i in seq(1, ESTIMATE_CALIBRATION + 10)) { # iterate to one past calibrated point
for (trial.i in seq(1, max(single.subj$trial))) { # over all trials
print(paste("trial: ", trial.i)) # show progress
#results$trial[trial.i] = c(results$trial, trial.i)
if (trial.i <= ESTIMATE_CALIBRATION) {
# set first ESTIMATE_CALIBRATION values to be a sample from a distribution around the true number of dots
# NB: samples in log space with low SD so that samples will be closer to real numbers at low n, farther at high n
# single.subj$answer_estimate[trial.i] = 10 ^ rnorm(1, log10(single.subj$num_dots[trial.i]), PERCEIVED_DOTS_NOISE_SD)
print(paste("-> estimate: ", single.subj$num_dots[trial.i]))
single.subj$answer_estimate[trial.i] = single.subj$num_dots[trial.i] # use exact number for debugging
} else {
# fetch previous trials for magnitude comparison
comparison.trials = seq(trial.i - ESTIMATE_CALIBRATION, trial.i - 1)
prev.vals = single.subj %>%
filter(trial %in% comparison.trials)
# compare magnitude of trial.i to previous trials
curr.trial.mag.mean = single.subj$num_dots[single.subj$trial == trial.i]
prev.vals = prev.vals %>%
mutate(p.mag.greater = 1 - pnorm(0, mean = log10(curr.trial.mag.mean) - log10(num_dots), sd = sqrt(2 * PERCEIVED_DOTS_NOISE_SD)))
# discretize possible answer estimates, set log likelihood at each value to be either p.mag.greater or 1 - p.mag.greater
# use matrix with a row for each of the previous trials and a column for each candidate estimate value.
# each row, col element in X is the log likelihood that the magnitude on the current trial maps to the column value, given the magnitude
#   and corresponding estimate in that row's trial
X = matrix(0, nrow = ESTIMATE_CALIBRATION, ncol = MAX_ESTIMATE) # Initialize matrix for storing log likelihoods
# matrix storing proability in each col that magnitude on this trial is < magnitude in trial indicated by that row
P = matrix(rep(1 - prev.vals$p.mag.greater[1:ESTIMATE_CALIBRATION], MAX_ESTIMATE), nrow = ESTIMATE_CALIBRATION)
# matrix storing numerical estimate generated for each previous trial
B = matrix(rep(floor(prev.vals$answer_estimate[1:ESTIMATE_CALIBRATION]), 1000), nrow = ESTIMATE_CALIBRATION)
X[A < B] = log10(P[A < B])
X[A >= B] = log10(1 - P[A >= B])
# across each previous trial that we've calculated a log likelihood vector for above, calculate aggregate likelihood for estimates
new.loglik = data.frame('number.est' = seq(1:MAX_ESTIMATE), 'sum.loglik' = colSums(X))
# process log likelihoods obtained above (add constant factor, re-convert to probability space, and normalize)
new.loglik = new.loglik %>%
mutate(prior = number.est ^ PRIOR_EXP,
prior.norm = prior / sum(prior),
sum.loglik = sum.loglik - max(sum.loglik),  #add a constant C to each value in new.loglik to make it more reasonable
loglik.probability.raw = 10 ^ sum.loglik, # reconvert out of log space
posterior.raw = loglik.probability.raw * prior.norm, # multiply loglik by the prior
posterior.norm = posterior.raw / sum(posterior.raw)) # normalize
# Three different ways of generating a number estimate are each included below (sample, posterior mean, posterior median)
# 1. sample estimate from the posterior
# estimate = with(new.loglik, sample(number.est, 1, prob = posterior.norm))
# 2. use the posterior mean as our estimate
# estimate = sum(new.loglik$number.est * new.loglik$posterior.norm)
# 3. use the median as our estimate (following Griffiths, Tenenbaum 2006)
estimate = new.loglik %>%
mutate(post_sum = cumsum(posterior.norm)) %>%
filter(post_sum <= 0.5) %>%
summarize(est = max(number.est)) %>%
pull(est)
results$estimate[trial.i] = estimate
print(paste("-> estimate: ", estimate))
print(paste("-> true number: ", single.subj$num_dots[single.subj$trial == trial.i]))
# print(paste("-> magnitude est: ", curr.trial.mag.mean))
single.subj$answer_estimate[single.subj$trial == trial.i] = estimate
}
}
results = data.frame('trial' = seq(1, max(single.subj$trial)),
'estimate' = 0,
'true number' = 0)
#for (trial.i in seq(1, ESTIMATE_CALIBRATION + 10)) { # iterate to one past calibrated point
for (trial.i in seq(1, max(single.subj$trial))) { # over all trials
print(paste("trial: ", trial.i)) # show progress
#results$trial[trial.i] = c(results$trial, trial.i)
if (trial.i <= ESTIMATE_CALIBRATION) {
# set first ESTIMATE_CALIBRATION values to be a sample from a distribution around the true number of dots
# NB: samples in log space with low SD so that samples will be closer to real numbers at low n, farther at high n
# single.subj$answer_estimate[trial.i] = 10 ^ rnorm(1, log10(single.subj$num_dots[trial.i]), PERCEIVED_DOTS_NOISE_SD)
#print(paste("-> estimate: ", single.subj$num_dots[trial.i]))
single.subj$answer_estimate[trial.i] = single.subj$num_dots[trial.i] # use exact number for debugging
} else {
# fetch previous trials for magnitude comparison
comparison.trials = seq(trial.i - ESTIMATE_CALIBRATION, trial.i - 1)
prev.vals = single.subj %>%
filter(trial %in% comparison.trials)
# compare magnitude of trial.i to previous trials
curr.trial.mag.mean = single.subj$num_dots[single.subj$trial == trial.i]
prev.vals = prev.vals %>%
mutate(p.mag.greater = 1 - pnorm(0, mean = log10(curr.trial.mag.mean) - log10(num_dots), sd = sqrt(2 * PERCEIVED_DOTS_NOISE_SD)))
# discretize possible answer estimates, set log likelihood at each value to be either p.mag.greater or 1 - p.mag.greater
# use matrix with a row for each of the previous trials and a column for each candidate estimate value.
# each row, col element in X is the log likelihood that the magnitude on the current trial maps to the column value, given the magnitude
#   and corresponding estimate in that row's trial
X = matrix(0, nrow = ESTIMATE_CALIBRATION, ncol = MAX_ESTIMATE) # Initialize matrix for storing log likelihoods
# matrix storing proability in each col that magnitude on this trial is < magnitude in trial indicated by that row
P = matrix(rep(1 - prev.vals$p.mag.greater[1:ESTIMATE_CALIBRATION], MAX_ESTIMATE), nrow = ESTIMATE_CALIBRATION)
# matrix storing numerical estimate generated for each previous trial
B = matrix(rep(floor(prev.vals$answer_estimate[1:ESTIMATE_CALIBRATION]), 1000), nrow = ESTIMATE_CALIBRATION)
X[A < B] = log10(P[A < B])
X[A >= B] = log10(1 - P[A >= B])
# across each previous trial that we've calculated a log likelihood vector for above, calculate aggregate likelihood for estimates
new.loglik = data.frame('number.est' = seq(1:MAX_ESTIMATE), 'sum.loglik' = colSums(X))
# process log likelihoods obtained above (add constant factor, re-convert to probability space, and normalize)
new.loglik = new.loglik %>%
mutate(prior = number.est ^ PRIOR_EXP,
prior.norm = prior / sum(prior),
sum.loglik = sum.loglik - max(sum.loglik),  #add a constant C to each value in new.loglik to make it more reasonable
loglik.probability.raw = 10 ^ sum.loglik, # reconvert out of log space
posterior.raw = loglik.probability.raw * prior.norm, # multiply loglik by the prior
posterior.norm = posterior.raw / sum(posterior.raw)) # normalize
# Three different ways of generating a number estimate are each included below (sample, posterior mean, posterior median)
# 1. sample estimate from the posterior
# estimate = with(new.loglik, sample(number.est, 1, prob = posterior.norm))
# 2. use the posterior mean as our estimate
# estimate = sum(new.loglik$number.est * new.loglik$posterior.norm)
# 3. use the median as our estimate (following Griffiths, Tenenbaum 2006)
estimate = new.loglik %>%
mutate(post_sum = cumsum(posterior.norm)) %>%
filter(post_sum <= 0.5) %>%
summarize(est = max(number.est)) %>%
pull(est)
single.subj$answer_estimate[single.subj$trial == trial.i] = estimate
# aggregate estimate and true number for later debugging
results$estimate[trial.i] = estimate
results$true.number[trial.i] = single.subj$num_dots[single.subj$trial == trial.i]
}
}
results = data.frame('trial' = seq(1, max(single.subj$trial)),
'estimate' = 0,
'true number' = 0)
#for (trial.i in seq(1, ESTIMATE_CALIBRATION + 10)) { # iterate to one past calibrated point
for (trial.i in seq(1, max(single.subj$trial))) { # over all trials
#print(paste("trial: ", trial.i)) # show progress
#results$trial[trial.i] = c(results$trial, trial.i)
if (trial.i <= ESTIMATE_CALIBRATION) {
# set first ESTIMATE_CALIBRATION values to be a sample from a distribution around the true number of dots
# NB: samples in log space with low SD so that samples will be closer to real numbers at low n, farther at high n
# single.subj$answer_estimate[trial.i] = 10 ^ rnorm(1, log10(single.subj$num_dots[trial.i]), PERCEIVED_DOTS_NOISE_SD)
#print(paste("-> estimate: ", single.subj$num_dots[trial.i]))
single.subj$answer_estimate[trial.i] = single.subj$num_dots[trial.i] # use exact number for debugging
} else {
# fetch previous trials for magnitude comparison
comparison.trials = seq(trial.i - ESTIMATE_CALIBRATION, trial.i - 1)
prev.vals = single.subj %>%
filter(trial %in% comparison.trials)
# compare magnitude of trial.i to previous trials
curr.trial.mag.mean = single.subj$num_dots[single.subj$trial == trial.i]
prev.vals = prev.vals %>%
mutate(p.mag.greater = 1 - pnorm(0, mean = log10(curr.trial.mag.mean) - log10(num_dots), sd = sqrt(2 * PERCEIVED_DOTS_NOISE_SD)))
# discretize possible answer estimates, set log likelihood at each value to be either p.mag.greater or 1 - p.mag.greater
# use matrix with a row for each of the previous trials and a column for each candidate estimate value.
# each row, col element in X is the log likelihood that the magnitude on the current trial maps to the column value, given the magnitude
#   and corresponding estimate in that row's trial
X = matrix(0, nrow = ESTIMATE_CALIBRATION, ncol = MAX_ESTIMATE) # Initialize matrix for storing log likelihoods
# matrix storing proability in each col that magnitude on this trial is < magnitude in trial indicated by that row
P = matrix(rep(1 - prev.vals$p.mag.greater[1:ESTIMATE_CALIBRATION], MAX_ESTIMATE), nrow = ESTIMATE_CALIBRATION)
# matrix storing numerical estimate generated for each previous trial
B = matrix(rep(floor(prev.vals$answer_estimate[1:ESTIMATE_CALIBRATION]), 1000), nrow = ESTIMATE_CALIBRATION)
X[A < B] = log10(P[A < B])
X[A >= B] = log10(1 - P[A >= B])
# across each previous trial that we've calculated a log likelihood vector for above, calculate aggregate likelihood for estimates
new.loglik = data.frame('number.est' = seq(1:MAX_ESTIMATE), 'sum.loglik' = colSums(X))
# process log likelihoods obtained above (add constant factor, re-convert to probability space, and normalize)
new.loglik = new.loglik %>%
mutate(prior = number.est ^ PRIOR_EXP,
prior.norm = prior / sum(prior),
sum.loglik = sum.loglik - max(sum.loglik),  #add a constant C to each value in new.loglik to make it more reasonable
loglik.probability.raw = 10 ^ sum.loglik, # reconvert out of log space
posterior.raw = loglik.probability.raw * prior.norm, # multiply loglik by the prior
posterior.norm = posterior.raw / sum(posterior.raw)) # normalize
# Three different ways of generating a number estimate are each included below (sample, posterior mean, posterior median)
# 1. sample estimate from the posterior
# estimate = with(new.loglik, sample(number.est, 1, prob = posterior.norm))
# 2. use the posterior mean as our estimate
# estimate = sum(new.loglik$number.est * new.loglik$posterior.norm)
# 3. use the median as our estimate (following Griffiths, Tenenbaum 2006)
estimate = new.loglik %>%
mutate(post_sum = cumsum(posterior.norm)) %>%
filter(post_sum <= 0.5) %>%
summarize(est = max(number.est)) %>%
pull(est)
single.subj$answer_estimate[single.subj$trial == trial.i] = estimate
# aggregate estimate and true number for later debugging
results$estimate[trial.i] = estimate
results$true.number[trial.i] = single.subj$num_dots[single.subj$trial == trial.i]
}
}
results
single.subj
# Analyze performance
results = single.subj %>%
select(trial, num_dots, answer_estimate)
results
# Analyze performance
results = single.subj %>%
select(trial, num_dots, answer_estimate) %>%
sort(trial)
# Analyze performance
results = single.subj %>%
select(trial, num_dots, answer_estimate) %>%
sort($.trial)
# Analyze performance
results = single.subj %>%
select(trial, num_dots, answer_estimate)
sort(results$trial)
results = sort(results$trial)
restuls
results
# Analyze performance
results = single.subj %>%
select(trial, num_dots, answer_estimate) %>%
order_by(trial)
# Analyze performance
results = single.subj %>%
select(trial, num_dots, answer_estimate) %>%
order_by(trial)
single.subj %>%
select(trial, num_dots, answer_estimate) %>%
order_by(trial)
# Analyze performance
results = single.subj %>%
select(trial, num_dots, answer_estimate) %>%
arrange(trial)
results
#for (trial.i in seq(1, ESTIMATE_CALIBRATION + 10)) { # iterate to one past calibrated point
for (trial.i in seq(1, max(single.subj$trial))) { # over all trials
if (trial.i <= ESTIMATE_CALIBRATION) {
# set first ESTIMATE_CALIBRATION values to be a sample from a distribution around the true number of dots
# NB: samples in log space with low SD so that samples will be closer to real numbers at low n, farther at high n
estimate = 10 ^ rnorm(1, log10(single.subj$num_dots[trial.i]), PERCEIVED_DOTS_NOISE_SD)
# estimate = single.subj$num_dots[trial.i] # use exact number for debugging
} else {
# fetch previous trials for magnitude comparison
comparison.trials = seq(trial.i - ESTIMATE_CALIBRATION, trial.i - 1)
prev.vals = single.subj %>%
filter(trial %in% comparison.trials)
# compare magnitude of trial.i to previous trials
curr.trial.mag.mean = single.subj$num_dots[single.subj$trial == trial.i]
prev.vals = prev.vals %>%
mutate(p.mag.greater = 1 - pnorm(0, mean = log10(curr.trial.mag.mean) - log10(num_dots), sd = sqrt(2 * PERCEIVED_DOTS_NOISE_SD)))
# discretize possible answer estimates, set log likelihood at each value to be either p.mag.greater or 1 - p.mag.greater
# use matrix with a row for each of the previous trials and a column for each candidate estimate value.
# each row, col element in X is the log likelihood that the magnitude on the current trial maps to the column value, given the magnitude
#   and corresponding estimate in that row's trial
X = matrix(0, nrow = ESTIMATE_CALIBRATION, ncol = MAX_ESTIMATE) # Initialize matrix for storing log likelihoods
# matrix storing proability in each col that magnitude on this trial is < magnitude in trial indicated by that row
P = matrix(rep(1 - prev.vals$p.mag.greater[1:ESTIMATE_CALIBRATION], MAX_ESTIMATE), nrow = ESTIMATE_CALIBRATION)
# matrix storing numerical estimate generated for each previous trial
B = matrix(rep(floor(prev.vals$answer_estimate[1:ESTIMATE_CALIBRATION]), 1000), nrow = ESTIMATE_CALIBRATION)
X[A < B] = log10(P[A < B])
X[A >= B] = log10(1 - P[A >= B])
# across each previous trial that we've calculated a log likelihood vector for above, calculate aggregate likelihood for estimates
new.loglik = data.frame('number.est' = seq(1:MAX_ESTIMATE), 'sum.loglik' = colSums(X))
# process log likelihoods obtained above (add constant factor, re-convert to probability space, and normalize)
new.loglik = new.loglik %>%
mutate(prior = number.est ^ PRIOR_EXP,
prior.norm = prior / sum(prior),
sum.loglik = sum.loglik - max(sum.loglik),  #add a constant C to each value in new.loglik to make it more reasonable
loglik.probability.raw = 10 ^ sum.loglik, # reconvert out of log space
posterior.raw = loglik.probability.raw * prior.norm, # multiply loglik by the prior
posterior.norm = posterior.raw / sum(posterior.raw)) # normalize
# Three different ways of generating a number estimate are each included below (sample, posterior mean, posterior median)
# 1. sample estimate from the posterior
# estimate = with(new.loglik, sample(number.est, 1, prob = posterior.norm))
# 2. use the posterior mean as our estimate
# estimate = sum(new.loglik$number.est * new.loglik$posterior.norm)
# 3. use the median as our estimate (following Griffiths, Tenenbaum 2006)
estimate = new.loglik %>%
mutate(post_sum = cumsum(posterior.norm)) %>%
filter(post_sum >= 0.5) %>%
summarize(est = min(number.est)) %>%
pull(est)
}
# add estimate to single.subj results
single.subj$answer_estimate[single.subj$trial == trial.i] = estimate
}
# Analyze performance
results = single.subj %>%
select(trial, num_dots, answer_estimate) %>%
arrange(trial)
results
# validating model answers
single.subj %>%
filter(trial > ESTIMATE_CALIBRATION) %>%
ggplot(aes(x = log10(num_dots))) +
geom_jitter(aes(y = log10(participant.answer)), color = 'blue', alpha = 0.5) +
geom_jitter(aes(y = log10(answer_estimate)),  color = 'red', alpha = 0.5) +
geom_abline() +
ggtitle(paste0("Model estimates, calibration = ", ESTIMATE_CALIBRATION)) +
labs(x = "Number presented (log10)", y = "Number estimated (log10)") +
theme(axis.title = element_text(size = 16, face = "bold"),
plot.title = element_text(size = 20, face = "bold"))
rm(list=ls())
